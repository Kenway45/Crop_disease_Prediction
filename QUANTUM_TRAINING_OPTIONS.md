# ğŸ”® Quantum Training Options Guide

## Overview

You have **5 different ways** to train quantum classifiers, ranging from ultra-fast toy examples to full production models.

---

## ğŸ¯ Quick Comparison

| Option | Time | Classes | Qubits | Purpose |
|--------|------|---------|--------|---------|
| **Toy** | 2-3 min | 3 | 4 | Quick test/learning |
| **Simple** | 5-10 min | 10 | 6 | Fast demo |
| **Standard** | 15-30 min | 45 | 8 | Production ready |
| **Full Training** | 2-4 hours | 45 | 8 | Complete retrain |
| **Custom** | Variable | Custom | Custom | Your own config |

---

## 1ï¸âƒ£ TOY Version (FASTEST - 2-3 minutes)

**Perfect for: Quick testing, learning, immediate results**

```bash
python train_quantum_toy.py
```

### What it does:
- âœ… Uses only **3 disease classes** (most common)
- âœ… **30 samples per class** (90 total)
- âœ… **4 qubits, 2 layers** (tiny circuit)
- âœ… **10 epochs**
- âœ… Training time: **~2-3 minutes**

### When to use:
- First time trying quantum ML
- Want immediate results
- Learning how quantum classifiers work
- Testing the setup

### Output:
```
âœ“ TOY Quantum Training Complete!

ğŸ‰ You just trained a quantum classifier!

What you learned:
  â€¢ Quantum circuits can classify data
  â€¢ Uses qubits and quantum gates
  â€¢ Trained with gradient descent
  â€¢ Achieved 55-70% accuracy on 3 classes
```

---

## 2ï¸âƒ£ SIMPLE Version (FAST - 5-10 minutes)

**Perfect for: Quick demos, presentations, testing**

```bash
python train_quantum_simple.py
```

### What it does:
- âœ… Uses **10 disease classes** (most common)
- âœ… **50 samples per class** (500 total)
- âœ… **6 qubits, 3 layers** (moderate circuit)
- âœ… **15 epochs**
- âœ… Training time: **~5-10 minutes**

### When to use:
- Need a working demo quickly
- Presenting quantum ML concepts
- Testing with realistic data
- Don't need all 45 classes

### Output:
```
âœ“ FAST Quantum Training Complete!

This quantum classifier:
  â€¢ Works on 10 disease classes (most common ones)
  â€¢ Uses 6 qubits and 3 layers
  â€¢ Achieved 60-75% accuracy
```

---

## 3ï¸âƒ£ STANDARD Version (RECOMMENDED - 15-30 minutes)

**Perfect for: Production use, full capability**

```bash
python train_quantum_only.py
```

### What it does:
- âœ… Uses **ALL 45 disease classes**
- âœ… **100 samples per class** (4,500 total)
- âœ… **8 qubits, 4 layers** (full circuit)
- âœ… **30 epochs**
- âœ… Training time: **~15-30 minutes**

### When to use:
- Want full quantum capability
- Production deployment
- Research paper
- Comparing with classical model

### Output:
```
âœ“ Quantum Classifier Training Complete!

âœ“ Train accuracy: 82.45%
âœ“ Test accuracy: 78.92%
âœ“ Saved to: artifacts/classifiers/quantum_clf.joblib

The server will now use BOTH classical and quantum predictions
```

---

## 4ï¸âƒ£ FULL TRAINING (COMPLETE - 2-4 hours)

**Perfect for: Complete retrain, starting from scratch**

```bash
python src/train_model.py
```

### What it does:
- âœ… Trains **CNN from scratch** (ResNet18)
- âœ… Extracts **all embeddings**
- âœ… Trains **PCA**
- âœ… Trains **classical classifier**
- âœ… Trains **quantum classifier** (8 qubits, 45 classes)
- âœ… Training time: **~2-4 hours**

### When to use:
- Starting completely fresh
- Have new dataset
- Want to retrain everything
- Research purposes

---

## 5ï¸âƒ£ CUSTOM Configuration

**Perfect for: Experimentation, research, specific needs**

### Create your own script:

```python
from quantum_classifier import QuantumClassifier

# Your custom configuration
quantum_clf = QuantumClassifier(
    n_features=128,      # From PCA
    n_classes=45,        # Or fewer
    n_qubits=10,         # More qubits = more capacity
    n_layers=6          # Deeper = more expressivity
)

quantum_clf.fit(
    X_train, 
    y_train,
    epochs=50,           # More epochs = better training
    batch_size=8,        # Smaller = slower but better
    learning_rate=0.01   # Adjust for convergence
)
```

### Parameters to adjust:

**Qubits:**
- More qubits = exponentially larger state space
- More expressivity but slower training
- Range: 4-12 (practical limit)

**Layers:**
- More layers = deeper circuit
- More complex patterns
- Range: 2-8

**Epochs:**
- More epochs = better convergence
- Diminishing returns after ~50
- Range: 10-100

**Batch size:**
- Smaller = better gradients, slower
- Larger = faster, noisier gradients
- Range: 4-32

---

## âš¡ Performance Comparison

### Training Speed:

```
Toy:      â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  2-3 min    (4 qubits, 3 classes)
Simple:   â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘  5-10 min   (6 qubits, 10 classes)
Standard: â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘  15-30 min  (8 qubits, 45 classes)
Full:     â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“  2-4 hours  (Complete retrain)
```

### Accuracy:

```
Toy:      â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘  55-70%  (Limited classes)
Simple:   â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘  60-75%  (10 classes)
Standard: â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘  75-85%  (All 45 classes)
Classical: â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“  92-96%  (For reference)
```

---

## ğŸš€ Recommended Workflow

### First Time:
1. Start with **TOY** (2-3 min) - understand quantum basics
2. Try **SIMPLE** (5-10 min) - see realistic performance
3. Run **STANDARD** (15-30 min) - get production model

### For Production:
- Use **STANDARD** version
- Integrated with demo server
- Provides both classical + quantum predictions

### For Research:
- Start with **STANDARD**
- Experiment with **CUSTOM** configurations
- Try different quantum architectures

---

## ğŸ® Try Right Now

### Fastest path (2 minutes):
```bash
python train_quantum_toy.py
```

### Best balance (5 minutes):
```bash
python train_quantum_simple.py
```

### Production ready (15 minutes):
```bash
python train_quantum_only.py
```

---

## ğŸ”¬ Understanding the Differences

### Why different versions?

**1. Problem Complexity:**
- 3 classes: Easier problem, faster training
- 10 classes: Moderate difficulty
- 45 classes: Full complexity

**2. Quantum Resources:**
- 4 qubits: 2â´ = 16 dimensional space
- 6 qubits: 2â¶ = 64 dimensional space
- 8 qubits: 2â¸ = 256 dimensional space

**3. Training Time:**
- Grows with: samples Ã— classes Ã— qubits Ã— layers Ã— epochs
- Toy: 90 samples Ã— simple circuit = fast
- Standard: 4,500 samples Ã— complex circuit = slower

---

## ğŸ’¡ Tips

### Speed up training:
```bash
# Reduce samples
max_samples_per_class = 50  # Instead of 100

# Reduce epochs
epochs = 15  # Instead of 30

# Increase batch size
batch_size = 32  # Instead of 16

# Reduce circuit size
n_qubits = 6    # Instead of 8
n_layers = 3    # Instead of 4
```

### Improve accuracy:
```bash
# More samples
max_samples_per_class = 200

# More epochs
epochs = 50

# Smaller batch size
batch_size = 8

# Larger circuit
n_qubits = 10
n_layers = 6
```

---

## ğŸ› Troubleshooting

### Training too slow?
- Use TOY or SIMPLE version
- Reduce epochs
- Reduce samples per class
- Increase batch size

### Not enough accuracy?
- Use STANDARD version
- More epochs
- More samples
- Deeper circuit (more layers)

### Out of memory?
- Reduce batch size
- Reduce qubits
- Use TOY version

### Want to stop training?
- Press Ctrl+C
- Training will stop gracefully
- No files will be corrupted

---

## ğŸ“Š Which One Should I Choose?

### Use TOY if:
- â° You have 2 minutes
- ğŸ“š Learning quantum ML
- ğŸ§ª Testing setup
- ğŸ® Want immediate results

### Use SIMPLE if:
- â° You have 5-10 minutes
- ğŸ¤ Giving a demo
- ğŸ”¬ Quick experiment
- âœ… Need something that works

### Use STANDARD if:
- â° You have 15-30 minutes
- ğŸš€ Production deployment
- ğŸ“Š Need all 45 classes
- ğŸ’¯ Want best quantum accuracy

### Use FULL if:
- â° You have 2-4 hours
- ğŸ”„ Starting from scratch
- ğŸ“ Have new data
- ğŸ“ Research project

---

## ğŸ¯ Summary

**Quick test:** `python train_quantum_toy.py`  
**Fast demo:** `python train_quantum_simple.py`  
**Production:** `python train_quantum_only.py`  
**Complete:** `python src/train_model.py`

**All versions work with your existing models and data!**

---

**Ready to train? Pick one and run it!** ğŸš€ğŸ”®

